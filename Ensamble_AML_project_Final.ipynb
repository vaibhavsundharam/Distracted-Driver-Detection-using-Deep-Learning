{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensamble_AML_project_Final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaibhavsundharam/Distracted-Driver-Detection-using-Deep-Learning/blob/master/Ensamble_AML_project_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_bhTuiSjmQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import sys\n",
        "import os\n",
        "from __future__ import print_function, division\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from skimage.transform import resize\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "plt.ion()   # interactive mode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ox-Mf9ttQ-3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "747b760a-771e-4e38-a020-e31a8a0dc91a"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvT32aAgtSYB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "648e0809-838c-42c0-d9df-f58517d414ca"
      },
      "source": [
        "# Set device on GPU if available, else CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB2F9HJmTkTB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f8236926-e98c-4788-8220-f71436061a95"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxyUEjWNTmXl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7332dfd9-986c-488f-d0b8-1bef6c14559c"
      },
      "source": [
        "prefix = '/content/gdrive/My Drive/'\n",
        "# modify \"customized_path_to_your_project\" \n",
        "customized_path_to_your_project = 'AML/Project/'\n",
        "sys_path = os.path.join(prefix, customized_path_to_your_project)\n",
        "sys.path.append(sys_path)\n",
        "print(f\"System path: {sys_path}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "System path: /content/gdrive/My Drive/AML/Project/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDTuXjRhUVAm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "3050dfca-57d7-4de7-a314-77dfbb57f4b5"
      },
      "source": [
        "# reading the CSV file with driver-class mapping for training\n",
        "root_dir = sys_path+\"Coding\"\n",
        "driver_imgs_csv = sys_path+\"Coding/CSV/driver_imgs_list.csv\"\n",
        "\n",
        "print(\"Root directory Location: {}\".format(root_dir)+\"\\n\")\n",
        "print(\"CSV file Location: {}\".format(driver_imgs_csv)+\"\\n\")\n",
        "\n",
        "\n",
        "drivers_imgs_file = pd.read_csv(driver_imgs_csv,engine='python')\n",
        "print(drivers_imgs_file)\n",
        "\n",
        "n=0\n",
        "img_name=drivers_imgs_file.iloc[n,2]\n",
        "img_class=drivers_imgs_file.iloc[n,1]\n",
        "print(\"Image name: {}\".format(img_name))\n",
        "print(\"Image class: {}\".format(img_class[1]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Root directory Location: /content/gdrive/My Drive/AML/Project/Coding\n",
            "\n",
            "CSV file Location: /content/gdrive/My Drive/AML/Project/Coding/CSV/driver_imgs_list.csv\n",
            "\n",
            "      subject classname            img\n",
            "0        p002        c0  img_44733.jpg\n",
            "1        p002        c0  img_72999.jpg\n",
            "2        p002        c0  img_25094.jpg\n",
            "3        p002        c0  img_69092.jpg\n",
            "4        p002        c0  img_92629.jpg\n",
            "...       ...       ...            ...\n",
            "22419    p081        c9  img_56936.jpg\n",
            "22420    p081        c9  img_46218.jpg\n",
            "22421    p081        c9  img_25946.jpg\n",
            "22422    p081        c9  img_67850.jpg\n",
            "22423    p081        c9   img_9684.jpg\n",
            "\n",
            "[22424 rows x 3 columns]\n",
            "Image name: img_44733.jpg\n",
            "Image class: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU0MzTaoAcPn",
        "colab_type": "text"
      },
      "source": [
        "# Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2QyzM6Me3Se",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DistractedDriverDataset(Dataset): # custom class to explore the dataset \n",
        "\n",
        "  def __init__(self, csv_file_loc, root_dir, transform=None):\n",
        "    self.driver_imgs_file = pd.read_csv(csv_file_loc) #  reading the CSV file\n",
        "    self.root_dir = root_dir # root directory of the images \n",
        "    self.transform = transform # transformations if any\n",
        "\n",
        "  def __len__(self):  # returns the length of the entire training set\n",
        "    return len(self.driver_imgs_file)\n",
        "\n",
        "  def __getitem__(self, idx):    \n",
        "    img_name=os.path.join(self.root_dir,self.driver_imgs_file.iloc[idx,1]) # featching the file name     \n",
        "    img_tensor=self.transform(Image.open(img_name)) # reading the image\n",
        "    \n",
        "     \n",
        "    \n",
        "    return img_tensor, img_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3mciPL3H0TZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''class DistractedDriverDataset(Dataset): # custom class to explore the dataset \n",
        "\n",
        "  def __init__(self, csv_file_loc, root_dir, transform=None):\n",
        "    self.driver_imgs_file = pd.read_csv(csv_file_loc) #  reading the CSV file\n",
        "    self.root_dir = root_dir # root directory of the images \n",
        "    self.transform = transform # transformations if any\n",
        "\n",
        "  def __len__(self):  # returns the length of the entire training set\n",
        "    return len(self.driver_imgs_file)\n",
        "\n",
        "  def __getitem__(self, idx):    \n",
        "    img_name=os.path.join(self.root_dir,self.driver_imgs_file.iloc[idx,1],self.driver_imgs_file.iloc[idx,2]) # featching the file name    \n",
        "     \n",
        "    driver_name=self.driver_imgs_file.iloc[idx,0] # driver name\n",
        "    #print(img_name, driver_name)\n",
        "    img_tensor=self.transform(Image.open(img_name)) # reading the image\n",
        "    \n",
        "    img_class=int(self.driver_imgs_file.iloc[idx,1][1])# fetching the image class \n",
        "    \n",
        "    return img_tensor, img_class  #img_name[64:77]   #,driver_name\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvoJza92Wich",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "0c482d48-92a6-464f-a991-94db36be3b8a"
      },
      "source": [
        "# Here we create two seperate instances of the Distracted driver data set. One will hold the data set for training and the other will hold data for validation\n",
        "\n",
        "print(\"Root directory:\",root_dir,\"\\n\")\n",
        "\n",
        "test_dataset=DistractedDriverDataset(csv_file_loc=\"/content/Test_csv.csv\",root_dir=root_dir+\"/Images/Test\",\n",
        "                                transform=transforms.Compose([transforms.Resize((244,244)),transforms.ToTensor()]))\n",
        "len_test_dataset=len(test_dataset)\n",
        "print(\"Total number of elements in training data:\", len_test_dataset)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Root directory: /content/gdrive/My Drive/AML/Project/Coding \n",
            "\n",
            "Total number of elements in training data: 69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6t30_j65gsI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f809be9f-43b4-49ad-94b9-84206b80953a"
      },
      "source": [
        "# loading training and validation data for the neural network\n",
        "test_loader=DataLoader(test_dataset, batch_size=32,shuffle=True, num_workers=16) # x.shape--->torch.Size([32, 3, 244, 244])\n",
        "\n",
        "'''for x, y in test_loader:\n",
        "  print(x.shape)\n",
        "  print(y[0][60:])'''\n",
        "  \n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'for x, y in test_loader:\\n  print(x.shape)\\n  print(y[0][60:])'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWnX4x8OSFTZ",
        "colab_type": "text"
      },
      "source": [
        "#Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXdyeG1mTm6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# solver function for NN training\n",
        "def Solver_NN (model, name, train_loader, optim, criterion, len_train_dataset, len_val_dataset, epoch=51, lr=1e-1):\n",
        "  print(\"Solver Initiated\")\n",
        "  model=model.to(device) # sending model to GPU\n",
        "  print(\"Model successfully sent to the GPU\\n\")  \n",
        "\n",
        "  train_acc_list=list()\n",
        "  val_acc_list=list()\n",
        "  epoch_list=list()\n",
        "  train_loss_list=list()\n",
        "  val_loss_list=list()\n",
        "  total_step = len(train_loader)\n",
        "  best_epoch=None\n",
        "  #curr_lr = learning_rate\n",
        "  counter=0\n",
        "  for e in range(epoch):\n",
        "    model.train()\n",
        "    loss_epoch=0     \n",
        "    epoch_list.append(e)   \n",
        "\n",
        "    for i,(x,y) in enumerate(train_loader):      \n",
        "      x = x.to(device)\n",
        "      y = y.to(device)    \n",
        "      #print(\"x is:\",x.shape)     \n",
        "      #print(\"y is:\",y.shape)\n",
        "\n",
        "      \n",
        "\n",
        "      #forward pass\n",
        "      y_pred=model(x)\n",
        "      #print(\"y_pred is:\",y_pred.shape)\n",
        "      loss=criterion(y_pred,y)\n",
        "      #print(\"loss:\",loss)\n",
        "\n",
        "      #bacward pass\n",
        "      optim.zero_grad()\n",
        "      #loss.to(device)\n",
        "      loss.backward()\n",
        "      optim.step()\n",
        "      \n",
        "      loss_epoch += float(loss.item())\n",
        "      #print(\"loss epoch:\",loss_epoch)    \n",
        "         \n",
        "      #print(f\"Training loss in epoch {e} is {(loss_epoch/len_train_dataset)*1000}\") \n",
        "      #train_loss_list.append((loss_epoch/len_train_dataset)*1000)\n",
        "\n",
        "      if (i+1) % 100 == 0:\n",
        "        print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\"\n",
        "                   .format(counter+1, epoch, i+1, total_step, loss.item()))\n",
        "    counter+=1\n",
        "      \n",
        "    print(f\"Training loss in epoch {e} is {(loss_epoch/len_train_dataset)*1000}\") \n",
        "    train_loss_list.append((loss_epoch/len_train_dataset)*1000)\n",
        "    model.eval()\n",
        "    with torch.no_grad():      \n",
        "      val_acc, val_loss = get_model_acc_and_loss(True,model,criterion,val_loader)\n",
        "      print(f\"Validation loss in epoch {e} is {(val_loss/len_val_dataset)*1000}\")\n",
        "      val_loss_list.append((val_loss/len_val_dataset)*1000)\n",
        "      train_acc = get_model_acc_and_loss(False,model,criterion,train_loader)\n",
        "      train_acc_list.append(train_acc)\n",
        "      val_acc_list.append(val_acc)\n",
        "      print(f'Validation accuracy: {val_acc}, Train accuracy: {train_acc}') \n",
        "\n",
        "      if best_epoch==None:\n",
        "        best_epoch=e        \n",
        "        best_val=val_acc\n",
        "        torch.save(model.state_dict(), root_dir+'/Saved Weights/'+name+\" epoch \"+str(e))\n",
        "        print(\"File saved successfully\\n\")\n",
        "      elif val_acc>best_val:\n",
        "        best_epoch=e        \n",
        "        best_val=val_acc\n",
        "        torch.save(model.state_dict(), root_dir+'/Saved Weights/'+name+\" epoch \"+str(e))\n",
        "        print(\"File saved successfully\\n\")\n",
        "      else:\n",
        "        print(\"\\n\")\n",
        "\n",
        "  print(f'Best epoch:{best_epoch}, Best Validtion accuracy:{best_val}')\n",
        "\n",
        "  fig, axs = plt.subplots(2)  \n",
        "  fig.tight_layout(pad=3.0)\n",
        "  axs[0].plot(epoch_list,train_acc_list, 'r--' ,epoch_list,val_acc_list,'g')\n",
        "  axs[0].set_title('Accuracy vs. epochs')  \n",
        "  axs[1].plot(epoch_list,train_loss_list, 'r--' ,epoch_list,val_loss_list,'g')\n",
        "  axs[1].set_title('Loss vs. epochs')\n",
        "  \n",
        "\n",
        "  plt.savefig(name+\".png\")\n",
        "\n",
        "  \n",
        "  \n",
        "  return model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7x47q8d1UlJF",
        "colab_type": "text"
      },
      "source": [
        "#Extra layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys5FJtPmU6lE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class extra_layer(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()               \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1000, 512),\n",
        "            nn.Linear(512, 10))\n",
        "    def forward(self, x):        \n",
        "        return self.fc(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhLxqGL4aZ-B",
        "colab_type": "text"
      },
      "source": [
        "##Ensamble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFrMWbPKLqfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Ensemble(nn.Module):\n",
        "    def __init__(self, modelA, modelB, modelC, modelD, modelE, nb_classes=10):\n",
        "        super(Ensemble, self).__init__()\n",
        "        self.modelA = modelA\n",
        "        self.modelB = modelB\n",
        "        self.modelC = modelC\n",
        "        self.modelD = modelD\n",
        "        self.modelE = modelE  \n",
        "    \n",
        "        \n",
        "    def forward(self, x):\n",
        "        A = self.modelA(x.clone())  # clone to make sure x is not changed by inplace methods\n",
        "        \n",
        "\n",
        "        B = self.modelB(x.clone())\n",
        "               \n",
        "\n",
        "        C = self.modelC(x.clone())\n",
        "        \n",
        "\n",
        "        D = self.modelD(x.clone())\n",
        "        \n",
        "\n",
        "        E = self.modelE(x)    \n",
        "\n",
        "        return A, B, C ,D ,E\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lhy9oD0MIXr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "f59f1c57-bdc4-4e1f-dcb7-71c475fc3622"
      },
      "source": [
        "\n",
        "modelA = nn.Sequential(torch.hub.load('pytorch/vision:v0.6.0', 'vgg16', pretrained=False), extra_layer())\n",
        "modelA.load_state_dict(torch.load(\"/content/gdrive/My Drive/AML/Project/Coding/With weights/Weights/VGG16 epoch 1\"))\n",
        "#print(modelA)\n",
        "\n",
        "modelB = nn.Sequential(torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=False), extra_layer())\n",
        "modelB.load_state_dict(torch.load(\"/content/gdrive/My Drive/AML/Project/Coding/With weights/Weights/RESNET18 epoch 8\"))\n",
        "#print(modelB)\n",
        "\n",
        "modelC = nn.Sequential(torch.hub.load('pytorch/vision:v0.6.0', 'resnet34', pretrained=False), extra_layer())\n",
        "modelC.load_state_dict(torch.load(\"/content/gdrive/My Drive/AML/Project/Coding/With weights/Weights/RESNET34 epoch 8 with weights\"))\n",
        "#print(modelC)\n",
        "\n",
        "modelD = nn.Sequential(torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=False), extra_layer())\n",
        "modelD.load_state_dict(torch.load(\"/content/gdrive/My Drive/AML/Project/Coding/With weights/Weights/ALEXNET epoch 9\"))\n",
        "#print(modelD)\n",
        "\n",
        "modelE = nn.Sequential(torch.hub.load('pytorch/vision:v0.6.0', 'mobilenet_v2', pretrained=False), extra_layer())\n",
        "modelE.load_state_dict(torch.load(\"/content/gdrive/My Drive/AML/Project/Coding/With weights/Weights/MOBILENET_V2 epoch 6\"))\n",
        "#print(modelE)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n",
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n",
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n",
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n",
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrDGcsHlajU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate ensamble\n",
        "model = Ensemble(modelA, modelB, modelC, modelD, modelE, nb_classes=10)\n",
        "\n",
        "#criterion and optimizer\n",
        "\n",
        "lr=1e-2\n",
        "criterion=nn.CrossEntropyLoss(reduction='mean') # loss criterion \n",
        "optim=torch.optim.SGD(model.parameters(), lr=lr) # optimizer "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaXcu7-6MMEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''def ensemble_model_acc(model, loader):      \n",
        "  ys=[]\n",
        "  y_predsA=[]\n",
        "  y_predsB=[]\n",
        "  y_predsC=[]\n",
        "  y_predsD=[]\n",
        "  y_predsE=[]  \n",
        "  model.to(device)  \n",
        "  for x, y in loader:    \n",
        "    x=x.to(device)\n",
        "    y=y.to(device)\n",
        "    ys.append(y)\n",
        "\n",
        "    y_predA, y_predB, y_predC, y_predD, y_predE=model(x)\n",
        "    \n",
        "    y_predsA.append(torch.argmax(y_predA, dim=1))\n",
        "    y_predsB.append(torch.argmax(y_predB, dim=1))\n",
        "    y_predsC.append(torch.argmax(y_predC, dim=1))\n",
        "    y_predsD.append(torch.argmax(y_predD, dim=1))\n",
        "    y_predsE.append(torch.argmax(y_predE, dim=1))\n",
        "  \n",
        "  \n",
        "  y_predA=torch.cat(y_predsA, dim=0)\n",
        "  y_predB=torch.cat(y_predsB, dim=0)\n",
        "  y_predC=torch.cat(y_predsC, dim=0)\n",
        "  y_predD=torch.cat(y_predsD, dim=0)\n",
        "  y_predE=torch.cat(y_predsE, dim=0)\n",
        "  \n",
        "  Y=torch.stack((y_predA, y_predB, y_predC, y_predC, y_predD, y_predE,y_predE ), dim=1)\n",
        "  y=torch.cat(ys, dim=0)\n",
        "\n",
        "  Y=Y.cpu()\n",
        "  y=y.cpu()\n",
        "  \n",
        "  Y=np.asarray(Y)\n",
        "  print(Y)\n",
        "  y=np.asarray(y)\n",
        "  print(y)\n",
        "  \n",
        "  combine=list() \n",
        "\n",
        "  for i in range(Y.shape[0]):\n",
        "      x=np.bincount(Y[i]).argmax()\n",
        "      combine.append(x)\n",
        "\n",
        "  \n",
        "  combine=np.asarray(combine)\n",
        "  print(combine)\n",
        "\n",
        "  ans=(y==combine).sum()/len(y)\n",
        "  print(ans)\n",
        "\n",
        "  return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vb8KxBLdIcod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ensemble_model_acc(model, loader):      \n",
        "  ys=[]\n",
        "  y_predsA=[]\n",
        "  y_predsB=[]\n",
        "  y_predsC=[]\n",
        "  y_predsD=[]\n",
        "  y_predsE=[] \n",
        "  img_names=[] \n",
        "  model.to(device)  \n",
        "\n",
        "  for x, y in loader:    \n",
        "    x=x.to(device)    \n",
        "    ys.append(y)    \n",
        "\n",
        "    y_predA, y_predB, y_predC, y_predD, y_predE=model(x)\n",
        "    \n",
        "    y_predsA.append(torch.argmax(y_predA, dim=1))\n",
        "    y_predsB.append(torch.argmax(y_predB, dim=1))\n",
        "    y_predsC.append(torch.argmax(y_predC, dim=1))\n",
        "    y_predsD.append(torch.argmax(y_predD, dim=1))\n",
        "    y_predsE.append(torch.argmax(y_predE, dim=1))\n",
        "  \n",
        "  \n",
        "  y_predA=torch.cat(y_predsA, dim=0)\n",
        "  y_predB=torch.cat(y_predsB, dim=0)\n",
        "  y_predC=torch.cat(y_predsC, dim=0)\n",
        "  y_predD=torch.cat(y_predsD, dim=0)\n",
        "  y_predE=torch.cat(y_predsE, dim=0)\n",
        "  \n",
        "  Y=torch.stack((y_predA, y_predB, y_predC, y_predC, y_predD, y_predE ), dim=1)\n",
        "  Y=Y.cpu()  \n",
        "  Y=np.asarray(Y)\n",
        "  print(Y)\n",
        "  \n",
        "  for i in range (len(ys)):\n",
        "    for loc in range(len(ys[i])):      \n",
        "      img_name=ys[i][loc]\n",
        "      img_names.append(img_name[60:])\n",
        "    \n",
        "  #print(f\"Image names: {img_names}\")\n",
        "\n",
        "  combine=list()\n",
        "  for i in range(Y.shape[0]):\n",
        "      x=np.bincount(Y[i]).argmax()\n",
        "      combine.append(x)\n",
        "\n",
        "  \n",
        "  combine=np.asarray(combine)\n",
        "  #print(combine)\n",
        "  \n",
        "  result=zip(img_names,combine)\n",
        "  print(list(result))\n",
        "  #ans=(y==combine).sum()/len(y)\n",
        "  #print(ans)\n",
        "\n",
        "  return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK2Pc5PgNCH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  test_acc = ensemble_model_acc(model, test_loader)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}